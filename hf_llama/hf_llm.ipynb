{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c727f52c-dc84-477e-bb7c-a4b4be071a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-12 09:00:24,867] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozhang/miniconda3/envs/py31/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8ee1e8b2df49b18603194fc775b07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StopTokenCriteria(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # 检查最新生成的 token 是否是停止标记\n",
    "        return input_ids[0, -1] in self.stop_token_id\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/dozhang/nlcmt1/HuggingfaceModels/Meta-Llama-3.1-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/dozhang/nlcmt1/HuggingfaceModels/Meta-Llama-3.1-8B-Instruct\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60801f4c-dcdc-4c06-b95b-e9d321c38f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|>Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\n",
      ">>>>\n",
      "Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them? (Round your answer to the nearest cent)\n",
      "## Step 1: Determine the cost of the first glass\n",
      "The cost of the first glass is $5.\n",
      "\n",
      "## Step 2: Determine the cost of the second glass\n",
      "The second glass costs 60% of $5. To find the cost, multiply 0.6 by $5.\n",
      "\n",
      "## Step 3: Calculate the cost of the second glass\n",
      "0.6 * $5 = $3.\n",
      "\n",
      "## Step 4: Determine the pattern for the cost of subsequent glasses\n",
      "Every second glass costs $3, and the rest cost $5.\n",
      "\n",
      "## Step 5: Calculate the number of glasses that cost $5 and the number of glasses that cost $3\n",
      "Since there are 16 glasses in total, and every second glass costs $3, we can divide the total number of glasses by 2 to find the number of glasses that cost $5 and the number of glasses that cost $3.\n",
      "\n",
      "## Step 6: Calculate the number of glasses that cost $5\n",
      "16 / 2 = 8 glasses that cost $5.\n",
      "\n",
      "## Step 7: Calculate the number of glasses that cost $3\n",
      "16 / 2 = 8 glasses that cost $3.\n",
      "\n",
      "## Step 8: Calculate the total cost of the glasses that cost $5\n",
      "8 * $5 = $40.\n",
      "\n",
      "## Step 9: Calculate the total cost of the glasses that cost $3\n",
      "8 * $3 = $24.\n",
      "\n",
      "## Step 10: Calculate the total cost of all the glasses\n",
      "Add the total cost of the glasses that cost $5 and the glasses that cost $3.\n",
      "\n",
      "## Step 11: Calculate the total cost\n",
      "$40 + $24 = $64.\n",
      "\n",
      "## Step 12: Round the total cost to the nearest cent\n",
      "Since $64 is already a whole number, there is no need to round.\n",
      "\n",
      "The final answer is: $\\boxed{64}$\n"
     ]
    }
   ],
   "source": [
    "# Encode input text\n",
    "input_text = \"<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nKylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "\n",
    "input_text = \"<|eot_id|>Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\"\n",
    "input_text = \"<|eot_id|>Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Create attention mask\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "# 定义停止条件\n",
    "stop_token_id = tokenizer.convert_tokens_to_ids([\"</s>\", \"<|eot_id|>\", \"<|end_of_text|>\", \"<|end_header_id|>\", \"<|start_header_id|>\"])\n",
    "stopping_criteria = StoppingCriteriaList([StopTokenCriteria(stop_token_id)])\n",
    "\n",
    "#import pdb; pdb.set_trace()\n",
    "# Generate text\n",
    "outputs = model.generate(inputs[\"input_ids\"], attention_mask=attention_mask, max_length=2048, num_return_sequences=1, \n",
    "                         pad_token_id=tokenizer.eos_token_id, stopping_criteria=stopping_criteria)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print (input_text)\n",
    "print (\">>>>\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82c1b8-da85-4903-b515-1772887ff143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
